{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc59ed3",
   "metadata": {},
   "source": [
    "# MFE 413: Data Analytics and Machine Learning\n",
    "\n",
    "## Problem Set 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79007988",
   "metadata": {},
   "source": [
    "### Cohort 2 Group 5\n",
    "* Chen Yechao\n",
    "* Chopra Aryan\n",
    "* Gonzalez Rivadeneira Sara\n",
    "* Jensen Mathieu\n",
    "* Kumar Pranay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05f7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a179c",
   "metadata": {},
   "source": [
    "# Question 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1784d10",
   "metadata": {},
   "source": [
    "### Simulate 1500 realizations of two uncorrelated standard Normal variables. Call the simulated variables $x_1$ and $x_2$ and use these simulated variables as your predictors for y. Simulate 1500 outcomes for y for each of the two models:\n",
    "\n",
    "### a) $1.5 x_1 - 2x_2 + \\epsilon$\n",
    "\n",
    "### b) $y=1.5x_1 -2x_2 + \\epsilon$, if $x_1 < 0$\n",
    "### $y= 1.5 $ ln $x_1 + \\epsilon$, if $x_1 \\geq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34766cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "n_train = 1000\n",
    "n_test = 500\n",
    "n_repeats = 500\n",
    "rng = np.random.default_rng(seed=42)\n",
    "mse_a = {'OLS': [], 'RF': [], 'XGB': []}\n",
    "mse_b = {'OLS': [], 'RF': [], 'XGB': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05f15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d898ed97",
   "metadata": {},
   "source": [
    "# Question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba061e6d",
   "metadata": {},
   "source": [
    "### Our goal in this exercise is to predict house prices in Boston (medv) given 11 explanatory variables (columns 1 through 11). Use the first 400 observations as your training sample and observations 401-506 as your test sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e7cfd0",
   "metadata": {},
   "source": [
    "#### (a) Use random forest with n_estimators=250 and max_depth=10. Once you run the random forest, use Pythonâ€™s rf.predict function to obtain predicted values for the test sample. What is the MSE of the prediction? Compare this to the benchmark MSE generated by a model that has as its predicted house value the mean house value in the test sample. As in the class notes, also report the Pseudo-R2 implied by these MSEs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1fc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('housing.csv')\n",
    "\n",
    "training = data.iloc[0:399]\n",
    "predictingTraining = training.drop(columns = ['medv'])\n",
    "labelsTraining = training.medv\n",
    "\n",
    "testing = data[400:]\n",
    "predictingTesting = testing.drop(columns = ['medv'])\n",
    "labelsTesting = testing.medv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07494de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=250,\n",
    "                           max_depth=10)\n",
    "rf.fit(predictingTraining, labelsTraining)\n",
    "prediction = rf.predict(predictingTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "015731cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of this prediciton is 16.9130881228398\n",
      "The psuedo R^2 is 0.6323003759967234\n"
     ]
    }
   ],
   "source": [
    "MSE_RF = np.mean(np.square((prediction - labelsTesting)))\n",
    "\n",
    "MSE_Baseline = np.mean(np.square((labelsTesting - np.mean(labelsTraining))))\n",
    "lm = LinearRegression().fit(predictingTraining, labelsTraining)\n",
    "lm_prediction = lm.predict(predictingTesting)\n",
    "MSE_lm = np.mean(np.square((lm_prediction - labelsTesting)))\n",
    "PseudoR2 = 1 - MSE_lm / MSE_Baseline\n",
    "\n",
    "print('MSE of this prediciton is', MSE_RF)\n",
    "print('The psuedo R^2 is', PseudoR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4038846",
   "metadata": {},
   "source": [
    "#### (b) Repeat the same exercise as above using XGBoost with learning_rate=0.1, gamma=0, max_depth=6. Use 10 folds and 200 rounds for the cross-validation procedure. Make sure that the output of the cross-validation procedure does not appear in your final write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a8b1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(booster = \"gbtree\",\n",
    "                                 objective = \"reg:squarederror\",\n",
    "                                 n_estimators = 200,\n",
    "                                 reg_lambda = 10,\n",
    "                                 gamma = 0,\n",
    "                                 learning_rate = 0.1,\n",
    "                                 max_depth=6)\n",
    "xgb_parm = xgb_regressor.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0a072f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of this prediciton is 20.36334406235749\n",
      "The psuedo R^2 is 0.8023093481951917\n"
     ]
    }
   ],
   "source": [
    "xgb_train = xgb.DMatrix(predictingTraining, label = labelsTraining)\n",
    "\n",
    "xgb_cvresult = xgb.cv(xgb_parm,\n",
    "                      xgb_train,\n",
    "                      metrics = \"rmse\",\n",
    "                      num_boost_round=200,\n",
    "                      nfold = 10,\n",
    "                      early_stopping_rounds=25)\n",
    "\n",
    "xgb_regressor.set_params(n_estimators = xgb_cvresult.shape[0])\n",
    "xgb_regressor.fit(predictingTraining, labelsTraining)\n",
    "\n",
    "xgb_prediction = xgb_regressor.predict(predictingTesting)\n",
    "\n",
    "MSE_xgb = np.mean(np.square((xgb_prediction - labelsTesting)))\n",
    "PseudoR2_xgb = 1 - MSE_xgb / MSE_Baseline\n",
    "\n",
    "print('MSE of this prediciton is', MSE_xgb)\n",
    "print('The psuedo R^2 is', PseudoR2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67895cc2",
   "metadata": {},
   "source": [
    "#### (c)  Repeat the exercise in part (a) using elastic net regression (l1_ratio=0.5). Use a cross-validation procedure to find an optimal lambda (alpha). For that exercise, split the training sample into quarters (i.e., the 4-fold cross-validation). Comment on the performance of the linear model relative to decision trees. In particular, get the MSE for the test sample and compute the Pseudo-R2 relative to the benchmark MSE from a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d3a20b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of this prediciton is 27.218328546143553\n",
      "The psuedo R^2 is 0.7357600453615478\n"
     ]
    }
   ],
   "source": [
    "elasticNetRegression = ElasticNetCV(l1_ratio=0.5,\n",
    "                                    cv=4)\n",
    "\n",
    "elasticNetRegression.fit(predictingTraining, labelsTraining)\n",
    "elasticPrediction = elasticNetRegression.predict(predictingTesting)\n",
    "\n",
    "MSE_elastic = np.mean(np.square((elasticPrediction - labelsTesting)))\n",
    "PseudoR2_elastic = 1 - MSE_elastic / MSE_Baseline\n",
    "\n",
    "print('MSE of this prediciton is', MSE_elastic)\n",
    "print('The psuedo R^2 is', PseudoR2_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be9a41",
   "metadata": {},
   "source": [
    "#### (d)  Try to figure out what the main sources of the discrepancy between Elastic Net and the decision trees are. That is, what is the non-linearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2198a38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
